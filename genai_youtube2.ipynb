{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xUisBg0GOExd",
        "outputId": "b678777a-eec7-47c1-ffbe-950ed68199b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m485.0/485.0 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit youtube-transcript-api langchain langchain-huggingface langchain-community faiss-cpu sentence-transformers pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Write your Streamlit app to a file ---\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write('''\n",
        "import streamlit as st\n",
        "import os\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings, ChatHuggingFace, HuggingFaceEndpoint\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from google.colab import userdata\n",
        "\n",
        "st.set_page_config(page_title=\"YouTube Video Q&A\", page_icon=\"ðŸ“º\", layout=\"wide\")\n",
        "\n",
        "if \"HUGGINGFACEHUB_API_TOKEN\" not in os.environ:\n",
        "    try:\n",
        "        os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"Hugging Face API token not found! Error: {e}\", icon=\"ðŸ”’\")\n",
        "        st.stop()\n",
        "\n",
        "@st.cache_data\n",
        "def get_transcript(video_url):\n",
        "    try:\n",
        "        video_id = video_url.split(\"v=\")[1].split(\"&\")[0]\n",
        "        ytt_api = YouTubeTranscriptApi()\n",
        "        transcript_list = ytt_api.list(video_id=video_id)\n",
        "        target_transcript = transcript_list.find_transcript(['en'])\n",
        "        transcript_data = target_transcript.fetch()\n",
        "        return \" \".join(chunk.text for chunk in transcript_data)\n",
        "    except TranscriptsDisabled:\n",
        "        st.error(\"Transcripts are disabled for this video.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        st.error(f\"Could not retrieve transcript. Error: {e}\")\n",
        "        return None\n",
        "\n",
        "@st.cache_resource\n",
        "def create_rag_chain(_transcript):\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = splitter.create_documents([_transcript])\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    vector_store = FAISS.from_documents(chunks, embeddings)\n",
        "    retriever = vector_store.as_retriever()\n",
        "    endpoint = HuggingFaceEndpoint(repo_id=\"HuggingFaceH4/zephyr-7b-beta\", max_new_tokens=512, temperature=0.1)\n",
        "    llm = ChatHuggingFace(llm=endpoint)\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a helpful assistant. Answer the question based ONLY on the provided context.\"),\n",
        "        (\"human\", \"CONTEXT:\\\\n{context}\\\\n\\\\nQUESTION:\\\\n{question}\")\n",
        "    ])\n",
        "    def format_docs(docs):\n",
        "        return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "    return rag_chain\n",
        "\n",
        "st.title(\"ðŸ“º YouTube Video Q&A Assistant\")\n",
        "st.markdown(\"Enter a YouTube video URL, and I'll answer your questions about it.\")\n",
        "\n",
        "if 'rag_chain' not in st.session_state:\n",
        "    st.session_state.rag_chain = None\n",
        "\n",
        "with st.sidebar:\n",
        "    st.header(\"Video Input\")\n",
        "    youtube_url = st.text_input(\"Enter YouTube URL:\", placeholder=\"https://www.youtube.com/watch?v=...\")\n",
        "    if st.button(\"Analyze Video\", type=\"primary\"):\n",
        "        if youtube_url:\n",
        "            with st.spinner(\"Fetching transcript and building knowledge base...\"):\n",
        "                transcript = get_transcript(youtube_url)\n",
        "                if transcript:\n",
        "                    st.session_state.rag_chain = create_rag_chain(transcript)\n",
        "                    st.success(\"Video analysis complete! You can now ask questions.\")\n",
        "        else:\n",
        "            st.warning(\"Please enter a YouTube URL.\")\n",
        "\n",
        "if st.session_state.rag_chain:\n",
        "    st.header(\"Ask a Question\")\n",
        "    question = st.text_input(\"What would you like to know?\", placeholder=\"e.g., What is the main topic of the video?\")\n",
        "    if question:\n",
        "        with st.spinner(\"Thinking...\"):\n",
        "            answer = st.session_state.rag_chain.invoke(question)\n",
        "            st.markdown(\"### Answer\")\n",
        "            st.write(answer)\n",
        "else:\n",
        "    st.info(\"Please analyze a video to start asking questions.\")\n",
        "''')\n"
      ],
      "metadata": {
        "id": "8IjLqKv2DWpO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b21f18e"
      },
      "source": [
        "# Find the process ID (PID) of the ngrok process\n",
        "!pkill ngrok\n",
        "\n",
        "# Verify that the process is no longer running\n",
        "!pgrep ngrok"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- Automatically fetch secrets ---\n",
        "# Ensure your secrets are named 'HF_TOKEN' and 'NGROK_TOKEN' in the Colab Secrets (ðŸ”‘) tab\n",
        "try:\n",
        "    hf_token = userdata.get('HF_TOKEN')\n",
        "    ngrok_token = userdata.get('ngrok_token')\n",
        "\n",
        "    if not hf_token or not ngrok_token:\n",
        "        raise ValueError(\"One or both tokens are not set in Colab Secrets.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error fetching secrets: {e}\")\n",
        "    print(\"Please ensure you have saved 'HF_TOKEN' and 'NGROK_TOKEN' in the Colab Secrets manager.\")\n",
        "else:\n",
        "    # Set the tokens for your app and ngrok\n",
        "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = hf_token\n",
        "    ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "    # Run streamlit in the background\n",
        "    !nohup streamlit run app.py &\n",
        "\n",
        "    # Create a public URL to the streamlit app\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(f\"Click this link to open your app: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsbUBcCFPKga",
        "outputId": "e4ea6851-d6f1-4a53-e388-2f45e8d97f5c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "Click this link to open your app: NgrokTunnel: \"https://3555f39cbc42.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BewjgzSJCpz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile app.py\n",
        "\n",
        "# import streamlit as st\n",
        "# import os\n",
        "# from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# from langchain_huggingface import HuggingFaceEmbeddings, ChatHuggingFace, HuggingFaceEndpoint\n",
        "# from langchain_community.vectorstores import FAISS\n",
        "# from langchain_core.prompts import ChatPromptTemplate\n",
        "# from langchain_core.runnables import RunnablePassthrough\n",
        "# from langchain_core.output_parsers import StrOutputParser\n",
        "# from google.colab import userdata\n",
        "\n",
        "# # --- App Configuration ---\n",
        "# st.set_page_config(\n",
        "#     page_title=\"YouTube Video Q&A\",\n",
        "#     page_icon=\"ðŸ“º\",\n",
        "#     layout=\"wide\"\n",
        "# )\n",
        "\n",
        "# # --- Hugging Face API Token ---\n",
        "# # For Streamlit Community Cloud, set the HF_TOKEN in the secrets manager\n",
        "# # For local development, you can use an environment variable\n",
        "# if \"HUGGINGFACEHUB_API_TOKEN\" not in os.environ:\n",
        "#     try:\n",
        "#         # Get the token from Colab secrets\n",
        "#         os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n",
        "#     except Exception as e:\n",
        "#         st.error(f\"Hugging Face API token not found! Please set it in your Colab secrets. Error: {e}\", icon=\"ðŸ”’\")\n",
        "#         st.stop()\n",
        "\n",
        "# # --- Caching Functions ---\n",
        "# # Use Streamlit's caching to avoid re-running expensive functions\n",
        "# @st.cache_data\n",
        "# def get_transcript(video_url):\n",
        "#     \"\"\"Fetches the transcript for a given YouTube video URL.\"\"\"\n",
        "#     try:\n",
        "#         # Extract video ID from URL\n",
        "#         video_id = video_url.split(\"v=\")[1].split(\"&\")[0]\n",
        "#         ytt_api = YouTubeTranscriptApi()\n",
        "#         transcript_list = ytt_api.list(video_id=video_id)\n",
        "#         target_transcript = transcript_list.find_transcript(['en'])\n",
        "#         transcript_data = target_transcript.fetch()\n",
        "#         return \" \".join(chunk.text for chunk in transcript_data)\n",
        "#     except TranscriptsDisabled:\n",
        "#         st.error(\"Transcripts are disabled for this video.\")\n",
        "#         return None\n",
        "#     except Exception as e:\n",
        "#         st.error(f\"Could not retrieve transcript. Please check the URL. Error: {e}\")\n",
        "#         return None\n",
        "\n",
        "# @st.cache_resource\n",
        "# def create_rag_chain(_transcript):\n",
        "#     \"\"\"Creates a RAG chain from the transcript text.\"\"\"\n",
        "#     # 1. Split text into chunks\n",
        "#     splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "#     chunks = splitter.create_documents([_transcript])\n",
        "\n",
        "#     # 2. Create embeddings and vector store\n",
        "#     embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "#     vector_store = FAISS.from_documents(chunks, embeddings)\n",
        "#     retriever = vector_store.as_retriever()\n",
        "\n",
        "#     # 3. Define the LLM\n",
        "#     # --- CORRECTED CODE ---\n",
        "#     # First, create the endpoint for the model\n",
        "#     endpoint = HuggingFaceEndpoint(\n",
        "#         repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
        "#         max_new_tokens=512,\n",
        "#         temperature=0.1\n",
        "#     )\n",
        "#     # Then, wrap it in the ChatHuggingFace class\n",
        "#     llm = ChatHuggingFace(llm=endpoint)\n",
        "#     # --- END OF CORRECTION ---\n",
        "\n",
        "#     # 4. Define the prompt template\n",
        "#     prompt = ChatPromptTemplate.from_messages([\n",
        "#         (\"system\", \"You are a helpful assistant. Answer the question based ONLY on the provided context. If the context is insufficient, just say you don't know.\"),\n",
        "#         (\"human\", \"CONTEXT:\\n{context}\\n\\nQUESTION:\\n{question}\")\n",
        "#     ])\n",
        "\n",
        "#     # 5. Build the RAG chain\n",
        "#     def format_docs(docs):\n",
        "#         return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "#     rag_chain = (\n",
        "#         {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "#         | prompt\n",
        "#         | llm\n",
        "#         | StrOutputParser()\n",
        "#     )\n",
        "#     return rag_chain\n",
        "\n",
        "# # --- Streamlit App UI ---\n",
        "# st.title(\"ðŸ“º YouTube Video Q&A Assistant\")\n",
        "# st.markdown(\"Enter a YouTube video URL, and I'll answer your questions about it.\")\n",
        "\n",
        "# # Initialize session state for the RAG chain\n",
        "# if 'rag_chain' not in st.session_state:\n",
        "#     st.session_state.rag_chain = None\n",
        "\n",
        "# with st.sidebar:\n",
        "#     st.header(\"Video Input\")\n",
        "#     youtube_url = st.text_input(\"Enter YouTube URL:\", placeholder=\"https://www.youtube.com/watch?v=...\")\n",
        "\n",
        "#     if st.button(\"Analyze Video\", type=\"primary\"):\n",
        "#         if youtube_url:\n",
        "#             with st.spinner(\"Fetching transcript and building knowledge base...\"):\n",
        "#                 transcript = get_transcript(youtube_url)\n",
        "#                 if transcript:\n",
        "#                     st.session_state.rag_chain = create_rag_chain(transcript)\n",
        "#                     st.success(\"Video analysis complete! You can now ask questions.\")\n",
        "#         else:\n",
        "#             st.warning(\"Please enter a YouTube URL.\")\n",
        "\n",
        "# # --- Q&A Section ---\n",
        "# if st.session_state.rag_chain:\n",
        "#     st.header(\"Ask a Question\")\n",
        "#     question = st.text_input(\"What would you like to know?\", placeholder=\"e.g., What is the main topic of the video?\")\n",
        "\n",
        "#     if question:\n",
        "#         with st.spinner(\"Thinking...\"):\n",
        "#             answer = st.session_state.rag_chain.invoke(question)\n",
        "#             st.markdown(\"### Answer\")\n",
        "#             st.write(answer)\n",
        "# else:\n",
        "#     st.info(\"Please analyze a video to start asking questions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "J1m--_myOOUT",
        "outputId": "4f8a6d9e-8830-4ed1-ba1b-88bda06f5b84"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    }
  ]
}